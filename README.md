<h1 align="center"> Case AB Inbev</h1>

## Reposit√≥rio destinado a constru√ß√£o do exerc√≠cio proposto como forma de avalia√ß√£o da empresa AB Inbev

<h4 align="center"> 
	üöß  AB Inbev Project üöÄ Conclu√≠do com pontos de melhorias..  üöß
</h4>

## √çndice 

* [T√≠tulo](#t√≠tulo)
* [√çndice](#√≠ndice)
* [Descri√ß√£o do Projeto](#descri√ß√£o-do-projeto)
* [Tecnologias utilizadas](#tecnologias-utilizadas)
* [Arquitetura](#arquitetura)
* [Resolu√ß√£o](#resolu√ß√£o)
* [Pontos de melhorias](#pontos-de-melhorias)
* [Monitoring/Alerting](#Monitoring/Alerting)
* [Execu√ß√£o do projeto](#execu√ß√£o-do-projeto)
* [Conclus√£o](#conclus√£o)
* [Autor](#autor)

## Descri√ß√£o do Projeto

Este projeto visa a resolu√ß√£o de um case proposto pela AB InBev como parte de um processo avaliativo. O objetivo √© desenvolver uma pipeline utilizando o conceito de camadas bronze, silver e gold para processar dados extra√≠dos de uma API.

### Etapas da Pipeline
- Camada Bronze:
    Os dados brutos s√£o extra√≠dos da API fornecida no case e armazenados na camada bronze, sendo inputados em seu formato bruto, sem quaisquer transforma√ß√µes.

- Camada Silver:
    A partir dos dados brutos da camada bronze, s√£o aplicadas as transforma√ß√µes necess√°rias para garantir a qualidade e o formato apropriado. Os dados transformados s√£o ent√£o gravados na camada silver, particionados por localidade.

- Camada Gold:
    Por fim, √© criada uma view na camada gold contendo informa√ß√µes agregadas sobre o n√∫mero de cervejarias, categorizadas por tipo e localidade. Esses dados s√£o salvos em formato otimizado.

### Formatos de Armazenamento
Os dados processados nas camadas silver e gold devem ser salvos nos formatos Parquet ou Delta.

### Orquestra√ß√£o
Para a orquestra√ß√£o da pipeline, √© necess√°rio escolher uma ferramenta adequada, como Airflow, Luigi, Mage, entre outras.

### Considera√ß√µes
Al√©m das transforma√ß√µes de dados, o projeto deve contemplar:

- Tratamento de falhas durante o processo.
- Monitoramento da qualidade dos dados.
- Garantia de robustez e confiabilidade na pipeline de dados.


## Tecnologias utilizadas 
:hammer:

- `Github`: Ferramenta utilizada para versionamento do projeto e reposit√≥rio;
- `Pyspark`: Linguagem para manipula√ß√£o dos arquivos e dados necess√°rios;
- `Python`: Linguagem para manipula√ß√£o dos arquivos e dados necess√°rios;
- `Docker`: Respons√°vel por criar a imagem necess√°ria para processamento da aplica√ß√£o;
- `Docker-compose`: Realiza a orquestra√ß√£o dos cont√™iners;
- `Airflow`: Organiza o fluxo de trabalho;
- `Bucket S3 - AWS`: Storage destinado ao armazenamento do fluxo de dados;

## Arquitetura

O projeto √© composto por duas DAG's, que ser√£o detalhadas mais adianta, por√©m como forma de melhor descri√ß√£o do processo, a arquitetura foi separada em dois desenhos mas podendo as duas estar√©m inseridas em um mesmo contexto.

![job_pandas](https://github.com/user-attachments/assets/22687081-09b5-4a90-b191-e6980f00e50d)
Na arquitetura podemos observar a inst√¢ncia do Airflow executada atrav√©s de uma imagem Docker, no caso um docker compose que permite que o Airflow rode todos os seus microservi√ßos necess√°rios para seu funcionamento. Atrav√©s de um PythonOperator executado pelo Airflow, √© poss√≠vel fazer uma requisi√ß√£o a API para consumo dos dados e inser√≠-los em um Bucker S3 na AWS (em camadas de acordo com contexto da aplicabilidade). Esse processo ser√° detalhado mais adiante.

![job_spark](https://github.com/user-attachments/assets/f7d2909e-8825-4ef0-94d5-407f37479021)
Na aquitetura acima, podemos observar a diferen√ßa pela inser√ß√£o do Spark no contexto. Diferentemente do fluxo anterior, nem todo processo ser√° executado dentro do ambiente do Airflow, as taks que fazem uso do Spark (iremos detalhar melhor adiante), ser√£o executadas atrav√©s de um DockerOperator, isso permite isolar parte da aplica√ß√£o para ser executada separadamente, assim evita poss√≠veis problemas como conflitos de vers√µes de bibliotecas e pacotes a serem instalados. J√° a parte repons√°vel pela inst√¢ncia do Airflow e task que utiliza do PythonOperator, ser√£o executadas igualmente a arquitetura anterior, como √© o caso da requisi√ß√£o na API. Importante ressaltar que o ambiente Spark realiza a comunica√ß√£o direta com Bucket S3, assim como o Airflow.

## Resolu√ß√£o

A primeira etapa para o desenvolvimento do projeto foi o desenho de como seria a arquitetura do processo de ponta a ponta, quais tecnologias seriam utilizadas, e que aspectos seriam necess√°rios para cobrir as exig√™ncias do case proposto.

- Ferramenta de Orquestra√ß√£o:
    Optou-se pelo uso do Airflow, devido a sua robustes para orquestra√ß√£o de tarefas, incluindo programa√ß√£o de tarefas, gest√£o de depend√™ncias, monitoramento para erros, configura√ß√£o de retries, al√©m da sua interface amig√°vel para monitoramento do processo.

- linguagem:
    Usou-se das linguagens python e pyspark para o desenvolvimento do case. Ambas as linguagens oferecem recursos importantes para acesso a API's e manipula√ß√£o de dados, sendo ambas compat√≠veis com o airflow.

<div style="color:red;">
    OBSERVA√á√ÉO IMPORTANTE NO DESENVOLVIMENTO DO PROJETO

  Ao realizar o teste, observou-se que os dados apresentavam baixa volumetria, apenas 50 linhas, o que tamb√©m permitiria o uso do pandas para realizar as transforma√ß√µes necess√°rias, sem que fosse preciso utilizar de uma ferramente de processamento distribu√≠do como Spark. Durante o desenvolvimento pode-se notar vantagens e desvantagens na utiliza√ß√£o de ambas as linguagens. Para manipula√ß√£o de baixo volume de dados, bibliotecas como o pandas s√£o muito satisfat√≥rias e atendem perfeitamente os requisitos necess√°rios, como tempo de processamento, libs, recursos, dentre outros, po≈ïem quando falamos de escrita e leitura de dados otimizados, inseridos em um datalake, como √© o caso do projeto, onde os dados s√£o inseridos em um Bucket S3, s√£o necess√°rias maiores etapas para se obter o mesmo resultado comparadas ao Spark. O spark, por sua vez, oferece maior controle de recursos, ferramentas importantes como lazy evaluation, catalyst, processamento distribu√≠do, dentre outros aspectos importantes, por√©m oferece maior complexidade em se provisionar o ambiente necess√°rio para sua execu√ß√£o, o que pode gerar multiplos conflitos e falta de deped√™ncias, contudo ap√≥s provisionado, oferece grande facilidade para transforma√ß√µes de dados, leitura e escrita de dados otimizados, n√£o sendo necess√°rias tantas etapas.

  Realizou-se o processo em uma DAG fazendo uso da biblioteca pandas e em outra fazendo uso do Spark, assim √© poss√≠vel notar as diferen√ßas entre os procesos. Embora fun√ß√µes como "to_pandas" e "spark.createDataFrame "pudessem ser utilizadas para combinar as solu√ß√µes, optou-se por manter as abordagens separadas devido aos fatores j√° mencionados.
</div>

- Containeriza√ß√£o: 
    Docker segue sendo um escolha interessante quando se trata de containers, j√° que √© a maior ferramenta utilizada e facilmente integrada em diversos projetos, permitindo a modulariza√ß√£o, garantindo a portabilidade da aplica√ß√£o, criando um pacote com sua depend√™ncias, permitindo que seja executada tanto localmente quanto em ambientes de nuvem.

- Monitoramento e alertas:
    O projeto foi desenvolvido de forma a criar v√°rios mecanismos para valida√ß√µes dos processos, utilizando do c√≥digo e de ferramentas nativas do pr√≥prio Airflow, como configura√ß√µes para retries, concurrency e envio de emails em caso de falha.

Desenhado a solu√ß√£o, seguiu-se com a resolu√ß√£o do case proposto. Descrevendo a solu√ß√£o por etapas:

- Task 1 (init_process_authentication):
    Criou-se essa task apenas como forma de simbolizar, que ambientes corporativos, sejam eles on premises ou em cloud services, costumam ser necess√°rio a autentica√ß√£o para acesso de leitura e escrita em datalakes, banco de dados, dentre outas coisas.

- Task 2 (extract_data_to_bronze):
    Nessa etapa fez-se a extra√ß√£o dos dados atrav√©s da biblioteca requests do python, realizando as devidas tratativas para erros e fazendo o input desses dados na camada bronze do datalake, criando-se um hist√≥rico segmentado por ano, m√™s e dia. Sendo os dados salvos no seu formato bruto, sem nenhuma tratativa respeitando o conceito da camada bronze.

- Task 3 (transform_bronze_to_silver):
    A partir dos dados inputados na camada bronze, realizou-se a limpeza, transforma√ß√µes e convers√£o nos dados, afim de torn√°-los mais perform√°ticos e facilitar em poss√≠veis an√°lises.

    Os dados foram lidos pelas bibliotecas pandas e pyspark, de acordo com a DAG em quest√£o, as transforma√ß√µes realizadas contemplam:

    - Upper Case no nome das colunas:
        Essa opera√ß√£o visa evitar poss√≠veis erros com cases senstive nas opera√ß√µes com dados
    - Upper case nos valores das colunas strings, exceto a coluna "id":
        Como no caso do nome das colunas, esse tipo de opera√ß√£o evita erros devido ao case senstive em opera√ß√µes realizadas com valores das colunas.
    - Elimina√ß√£o de espa√ßos nulos a esquerda e direita:
        A√ß√£o importante na mitiga√ß√£o de erros nas opera√ß√µes com dados, visto que nem sempre √© poss√≠vel perceber um espa√ßo vazio a esquerda ou direita.
    - Tratamento para valores nulos:
        Necess√°rio a adequa√ß√£o aos valores nulos, devido a tamb√©m possibilidade de erros a manipular esse tipo de dados, atendo-se sempre a n√£o ter perda de informa√ß√£o nas etapas de limpeza e tratamento dos dados.
    - Salvar em formato parquet particionado por localidade:
        Etapa final da etapa realizada, onde faz-se o input das informa√ß√µes na camada silver do datalake, particionando os dados por localidade, no caso optou-se por particionar por "COUNTRY", "STATE" e "CITY", assim √© poss√≠vel ler dados somente de determinado pa√≠s, estado ou cidade.

- Task 4 (transform_silver_to_gold):
    Devido aos dados j√° terem sido limpos e tratados na etapa anterior, nessa faz-se necess√°rio somente o check da integridade dos dados, e assim pode-se fazer as a√ß√µes propostas nessa etapa.

    Tamb√©m como na etapa anterior os dados foram lidos pelas bibliotecas pandas e pyspark, de acordo com a DAG em quest√£o.

    - Inferiu-se o schema nos dados: 
        Essa etapa foi necess√°ria devido √† leitura de dados em uma camada particionada, que pode alterar o tipo de dado originalmente salvo, resultando em inconsist√™ncias nas etapas seguintes. Portanto, ao realizar a leitura, assegura-se que os dados mantenham o mesmo schema utilizado na task anterior.
      
    - Cria√ß√£o de view de quantidade de cervejaria, por tipo de localidade:
        Aplicou-se o metodo groupby nas colunas "BREWERY_TYPE", "COUNTRY", "STATE" e "CITY", assim podemos obter a visualiza√ß√£o pedida no case proposto.

<span style="color:red">
    NOTA

  Ao se falar localidade, pode-se ter diferentes entendimentos, como somente o pa√≠s, estado ou a cidade. Em um case real pode-se averiguar essa informa√ß√£o e chegar em uma solu√ß√£o ideal que ir√° atender a fins espec√≠ficos, no caso fez-se a escolha que julgou-se melhor para o case.
</span>

Dentro das tasks aplicou-se em c√≥digo, valida√ß√µes, tratativas para erros e exce√ß√µes, estes que podem ser observados em logs do Airflow, assim como em caso de falha serem executados novamente.

Obs: O hist√≥rico dos dados √© mantido somente na camada bronze, j√° as camadas silver e gold foram criadas de forma a fornecer uma visualiza√ß√£o di√°rias desses dados, ou seja, ir√£o disponibilizar somente os dados extra√≠dos no dia da execu√ß√£o. Em um processo real, poderiam-se avaliar outros cen√°rios onde seria poss√≠vel tamb√©m trazer uma visualiza√ß√£o com hist√≥rico tamb√©m nessas camadas, ou mesmo com um intervalo de dados melhor definido, como por exemplo os dados dos √∫ltimos 2 anos.

## Monitoring/Alerting:
Em um ambiente de produ√ß√£o, √© fundamental implementar mecanismos eficazes de monitoramento e alertas para garantir a estabilidade, integridade, robustez e efici√™ncia do pipeline. Abaixo est√£o algumas pr√°ticas que podem ser eficazes:

- Alertas em Tempo Real: 
    Configura√ß√£o de notifica√ß√µes autom√°ticas para falhas e erros via e-mail, SMS, ou ferramentas corporativas como Microsoft Teams ou Slack, garantindo uma resposta r√°pida a problemas.

- Dashboards de Monitoramento: 
    Uso de ferramentas como Grafana para criar dashboards que exibam o desempenho e o status das DAGs, proporcionando visibilidade cont√≠nua do pipeline.

No projeto atual como medida de monitoramento, criou-se uma camada de servi√ßos para realizar telemetria e monitoramento de recursos da infraestrutura utilizados pelo sistema. Esses servi√ßos s√£o:
	- Prometheus: Servi√ßo usado para coleta de logs e m√©tricas utilizadas na telemetria e monitoramento;
	- Grafana: Servi√ßo usado para visualiza√ß√£o de logs e m√©tricas coletadas pelo Prometheus, provendo dashboards para monitoramento;
	- Prometheus Agents e Exporters: Servi√ßos respons√°veis por coletar m√©tricas de enviar para o Prometheus. Os agentes utilizados nesse trabalho foram:
		- Node exporter: Agente para coletar dados de telemetria do n√≥ em espec√≠fico.
		- Cadvisor: Agente para coletar dados de telemetria do docker.

Assim, ap√≥s implementado a parte de monitoramento, tem-se:
	- Os exporters coletam essas m√©tricas e as enviam para o Prometheus.
	- O Grafana consome essas m√©tricas do Prometheus e as exibe em dashboards.

Nota:
	- Na parte de execu√ß√£o do sistema, ser√° informado como implementar a solu√ß√£o no ambiente e visualizar os Dashboards.

- Otimiza√ß√£o de Recursos: 
    Em ambientes como Kubernetes, ajustar o executor_config nas DAGs do Airflow para alocar recursos de maneira eficiente, evitando tanto o uso excessivo quanto o subdimensionamento de recursos, o que pode resultar em custos desnecess√°rios ou falhas frequentes.

Essas s√£o apenas algumas das solu√ß√µes poss√≠veis para implementar monitoramento e alertas em pipelines de dados.

## Pontos de melhorias
Pode-se destacar alguns pontos de melhoria para o desenvolvimento do projeto:

Provisionamento de ambientes segregados - de acordo com a branch em execu√ß√£o (ex: main, hml, prd), poderia-se realizar o deploy para diferentes inst√¢ncias, o que possibilitaria uma simula√ß√£o de ambientes de desenvolvimento, homologa√ß√£o e produ√ß√£o.

Github Actions - implementa√ß√£o de ferramenta de CI/CD, tamb√©m sendo poss√≠vel valida√ß√µes como CodeQL, Lint, Flake, Blake nos "pushs" das branchs.

Catalogo de dados - assim teria-se melhor visualiza√ß√£o dos dados inputados nas camadas bronze, silver e gold.

Testes Unit√°rios - A realiza√ß√£o de testes unit√°rios para os c√≥digos desenvolvidos, assim seria poss√≠vel tamb√©m validar a integridade das aplica√ß√µes.

Great Expectations - em um caso real, poderia-se implementar uma valida√ß√£o em cima dos dados consumidos ou inseridos no datalake, de acordo com alguma regra de neg√≥cio estipulado pelos Stakeholders.

## Execu√ß√£o do projeto 
üìÅ 

Para execu√ß√£o completa do projeto, seguir os passos descritos abaixo:

  - Clonar o reposit√≥rio do projeto:
	```sh
	git clone https://github.com/netomadazio/breweries_case_abinbev.git

  - Verifica√ß√£o da branch:
	```sh
	git status

  - Caso n√£o encontrar-se na branch main, realizar a mudan√ßa para branch principal:
    ```sh
    git checkout main

  - Executar os comandos abaixo, para que o Airflow tenha permiss√£o nos diret√≥rios em quest√£o e tamb√©m tenha permiss√£o para provisionar cont√™iners Docker:
  -		
	```sh
	sudo chmod -R 777 ./mnt/airflow/logs
  -    
	```sh
	sudo chmod -R 777 ./mnt/airflow/dags
  -  
	```sh
	sudo chmod -R 777 ./mnt/airflow/plugins
  -	
	```sh
	sudo chmod -R 777 /var/run/docker.sock

Ap√≥s os passos anteriores √© necess√°rio a cria√ß√£o das imagens utilizadas para a execu√ß√£o do projeto.

  - Utilizando-se do arquivo Makefile, podemos executar os comandos a seguir para inst√¢nciar toda nossa infraestrutura e executar nosso projeto:
    - build da imagem do Airflow:
      ```sh
      make build_airflow
    - build da imagem do Spark:
      ```sh
      make build_spark_apps

    Ap√≥s finalizado o build das imagens acima √© poss√≠vel realizar os passos adiante.

  - Instanciar o ambiente Spark e Airflow:
    - Executar ambiente Airflow:
      ```sh
      make deploy_airflow
    - Executar ambiente Spark:
      ```sh
      make deploy_airflow

    Pode-se verficar se os ambientes foram provisionados atrav√©s dos comandos:
    - Para ambiente Airflow:
      ```sh
      make watch_airflow
    - Para ambiente Spark:
      ```sh
      make watch_airflow

Ap√≥s verificar que os ambientes est√£o em execu√ß√£o, voc√™ pode acessar a interface do Airflow pelo endere√ßo "http://localhost:8080/". Nela, as DAGs podem ser executadas e os logs de suas execu√ß√µes monitorados.

Para que as DAGs funcionem corretamente, √© necess√°rio criar uma "connection" no Airflow, garantindo o acesso √†s credenciais do bucket S3 na AWS. Para isso, siga os seguintes passos:

- 1 - Clique em "Admin" na parte superior da interface do Airflow.
- 2 - Selecione "Connections".
- 3 - No campo "Conn Id", insira "aws_access_abinbev".
- 4 - No campo "Conn Type", procure por "S3".
- 5 - Preencha os campos "Login" e "Password" com a access key e a secret key da AWS.
- 6 - Clique em "Salvar".
Com a conex√£o configurada, as DAGs j√° podem ser executadas no ambiente do Airflow.

No caso do processo executado com Spark, sua interface tamb√©m pode ser acessada para visualizar os jobs Spark em andamento e os recursos alocados, atrav√©s do endere√ßo "http://localhost:8090/".

### Implementando a parte de monitoramento

Para que seja poss√≠vel visualizar as metricas do sistema e dos cont√™iners acima, √© necess√°rio a implementa√ß√£o do nosso sistema de monitoramento fazendo uso do Prometheus e Grafana. Para isso √© necess√°rio seguir os passos abaixo:
	Executar o seguinte comando:
 	- 
	  ```sh
	  make deploy_monitoring

Com isso os servi√ßos necess√°rio para o monitoramento ser√£o instanciados, √© poss√≠vel observar os status dos servi√ßos executando:
	Executar o seguinte comando:
  	- 
	  ```sh
	  make watch_monitoring

Ap√≥s instanciado, √© poss√≠vel ent√£o realizar a cria√ß√£o dos Dashboards no grafana.

### Adicionando dashboards ao Grafana

A interface do Grafana pode ser acessada no navegador, digitando o endere√ßo http://localhost:3000. O usu√°rio e senha padr√£o s√£o admin e admin, respectivamente.

Para adicionar o dashboard do Node Exporter e do Docker, clique em "Dashboards" no lado esquerdo da tela, e depois em Import. No campo Grafana.com Dashboard digite o n√∫mero 1860 e clique em Load. Em seguida, selecione o Prometheus como fonte de dados e clique em Import.

Obs: Caso n√£o tenha dispon√≠vel o Prometheus como Data Source, criar a connection e no campo URL do Prometheus passar o endere√ßo "http://prometheus:9090", isso habilitar√° a conex√£o do Grafana com o Prometheus, assim ser√° poss√≠vel consumir as metricas e criar o Dashboard.

Para adicionar o dashboard referente ao Docker, repita o processo usando o ID 193 no campo Grafana.com Dashboard.

Ap√≥s realizado os passos acima, ser√° poss√≠vel visualizar as m√©tricas de sistema e cont√™iners Docker como as imagens demonstradas abaixo.

System Monitoring
![dashboard_system_monitoring](https://github.com/user-attachments/assets/81ace25b-73f3-49da-b4b4-321c2af7a276)

Docker Monitoring
![dashboard_docker_monitoring](https://github.com/user-attachments/assets/b171da22-af9b-4d2d-95d5-e3034618be42)


Finalizadas as execu√ß√µes, pode-se desativar os ambientes atrav√©s dos comandos abaixo:
  - Desativando ambiente Airflow:
    ```sh
    make stop_airflow
  - Desativando ambiente Spark:
    ```sh
    make stop_spark
  - Desativando ambiente de monitoramento:
    ```sh
    make stop_monitoring

Processo finalizado.

## Conclus√£o

Atrav√©s do trabalho proposto, pode-se desenvolver um fluxo completo de ETL utilizando-se de algumas ferramentas dispon√≠veis no mercado, ficando como observa√ß√£o a possibilidade de realizar melhorias nas etapas executadas, construindo um melhor desenvolvimento, execu√ß√£o e entrega.
Agrade√ßo desde j√° pela oportunidade e sigo a disposi√ß√£o para quaisquer questionamentos.
Muito obrigado, AB Inbev.

Atenciosamente,

### Autor

Irineu Madazio Neto,
Engenheiro de Controle e Automa√ß√£o
S√™nior Data Engineer
apaixonado pela √°rea de Engenharia de Dados.

[![Linkedin Badge](https://img.shields.io/badge/-Irineu-blue?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/in/irineu-madazio-neto/)](https://www.linkedin.com/in/irineu-madazio-neto/) 
